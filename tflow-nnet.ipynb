{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, cross_validation\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "sample = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['pitcher_id', 'batter_id', 'away_team', 'home_team', \n",
    "                'year', 'b_stand', 'p_throws', 'inning_half',  \n",
    "                'batter_team', 'pitcher_team', 'type']\n",
    "real_features = ['night', 'inning', 'order', 'home', 'weekday', \n",
    "                 'month', 'balls', 'strikes', 'sz_top', 'sz_bot']\n",
    "n_cat = len(cat_features) - 1 # -1 for type\n",
    "n_real = len(real_features)\n",
    "ptypes = sample.type.unique()\n",
    "depths = [len(data[col].unique()) for col in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = len(sample)\n",
    "n_outputs = len(ptypes)\n",
    "embedding_size = 30\n",
    "prep = learn.preprocessing.CategoricalProcessor()\n",
    "cat_data = np.array(list(prep.fit_transform(sample[cat_features])))\n",
    "n_pitchers = cat_data[:,0].max() + 1\n",
    "n_batters = cat_data[:,1].max() + 1\n",
    "\n",
    "real_data = sample[real_features].values\n",
    "result_data = cat_data[:,-1]\n",
    "cat_data = cat_data[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_embeddings = tf.Variable(tf.random_uniform([n_pitchers, embedding_size], -1.0, 1.0))\n",
    "b_embeddings = tf.Variable(tf.random_uniform([n_batters, embedding_size], -1.0, 1.0))\n",
    "\n",
    "cat_batch = tf.placeholder(tf.int32, [None, n_cat])\n",
    "real_batch = tf.placeholder(tf.float32, [None, n_real])\n",
    "result_batch = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "pitchers = cat_batch[:,0]\n",
    "batters = cat_batch[:,1]\n",
    "\n",
    "p_embed = tf.nn.embedding_lookup(p_embeddings, pitchers)\n",
    "b_embed = tf.nn.embedding_lookup(b_embeddings, batters)\n",
    "\n",
    "inputs = [p_embed, b_embed, real_batch]\n",
    "for i in range(2, n_cat):\n",
    "    inputs.append(tf.one_hot(cat_batch[:,i], depth=depths[i],\n",
    "                  on_value=1.0, off_value=0.0, dtype=tf.float32))\n",
    "input_layer = tf.concat(concat_dim=1, values=inputs)\n",
    "\n",
    "in_dim = input_layer.get_shape()[1]\n",
    "\n",
    "W1 = tf.Variable(tf.zeros([in_dim, 75]))\n",
    "b1 = tf.Variable(tf.zeros([75]))\n",
    "\n",
    "hidden = tf.nn.relu(tf.matmul(input_layer, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.zeros([75, n_outputs]))\n",
    "b2 = tf.Variable(tf.zeros([n_outputs]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(hidden, W2) + b2)\n",
    "y_ = tf.one_hot(indices=result_batch, depth=n_outputs, \n",
    "                on_value=1.0, off_value=0.0, dtype=tf.float32)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2156\n",
      "1.84501\n",
      "1.87403\n",
      "2.0088\n",
      "1.78635\n",
      "1.86596\n",
      "1.98808\n",
      "1.86645\n",
      "1.95474\n",
      "1.89324\n",
      "1.88269\n",
      "1.81515\n",
      "1.90046\n",
      "1.86563\n",
      "1.96399\n",
      "1.94041\n",
      "1.98976\n",
      "1.88657\n",
      "1.92241\n",
      "1.86227\n",
      "1.95941\n",
      "1.92507\n",
      "1.96407\n",
      "1.78848\n",
      "1.92578\n",
      "1.77164\n",
      "1.9423\n",
      "1.90178\n",
      "1.86012\n",
      "1.92233\n",
      "1.89106\n",
      "1.89043\n",
      "1.79072\n",
      "1.91971\n",
      "1.85136\n",
      "1.97118\n",
      "1.93519\n",
      "1.88611\n",
      "1.8199\n",
      "1.84727\n",
      "1.83663\n",
      "1.93284\n",
      "1.72864\n",
      "1.75813\n",
      "1.81995\n",
      "2.06889\n",
      "1.79074\n",
      "1.76029\n",
      "1.92533\n",
      "1.9499\n",
      "1.89887\n",
      "1.96366\n",
      "1.91524\n",
      "1.77349\n",
      "1.86969\n",
      "1.931\n",
      "1.89294\n",
      "2.01398\n",
      "1.90457\n",
      "1.88455\n",
      "1.75282\n",
      "1.78378\n",
      "1.823\n",
      "1.9278\n",
      "1.81076\n",
      "1.99548\n",
      "1.9111\n",
      "1.82358\n",
      "1.84163\n",
      "1.97825\n",
      "1.73871\n",
      "1.82709\n",
      "1.90067\n",
      "1.82791\n",
      "1.8393\n",
      "1.81595\n",
      "1.90053\n",
      "1.91563\n",
      "1.80612\n",
      "1.71503\n",
      "1.99787\n",
      "1.85574\n",
      "1.85874\n",
      "1.75967\n",
      "1.83699\n",
      "1.74668\n",
      "1.82854\n",
      "1.83684\n",
      "1.91736\n",
      "1.86353\n",
      "1.90647\n",
      "1.90214\n",
      "1.91601\n",
      "1.89341\n",
      "1.81655\n",
      "1.92413\n",
      "1.84993\n",
      "1.82894\n",
      "1.82711\n",
      "1.82604\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "batch_size = 100\n",
    "for i in range(10000):\n",
    "    idx = np.random.randint(0, data.shape[0], batch_size)\n",
    "    input_data = feed_dict={cat_batch : cat_data[idx],\n",
    "                                        real_batch : real_data[idx], \n",
    "                                        result_batch : result_data[idx]}\n",
    "    sess.run(train_step, feed_dict=input_data)\n",
    "    if i % 100 == 0:\n",
    "        print(sess.run(cross_entropy, feed_dict=input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
